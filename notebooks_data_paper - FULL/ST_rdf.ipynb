{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ccfe1be-27ef-4c58-9b1f-d17590588ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from subprocess import check_output\n",
    "import shutil\n",
    "import rdflib\n",
    "from multiprocessing import Process, Manager, Queue\n",
    "import multiprocessing\n",
    "\n",
    "from rule import *\n",
    "from amie import *\n",
    "from experiment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d339699-ef25-4e14-ab90-1539b8a65b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_source_FB = \"./../../FB15k_mail/\"\n",
    "root_source_DB = \"./../../DB15k_mail/\"\n",
    "\n",
    "root_data_FB = \"./../../Data_mail/FB_ST_\"\n",
    "root_data_DB = \"./../../Data_mail/DB_ST_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cd6d1-909f-4936-bccc-67dfdac2e699",
   "metadata": {},
   "source": [
    "# FB15K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4e20cb-244b-494b-8a4e-7c10cf6e3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(root_source_FB+\"numericals.txt\", \"r\")\n",
    "\n",
    "numerical_predicate = set()\n",
    "\n",
    "for predicate in data:\n",
    "    numerical_predicate.add(predicate.split(\"\\n\")[0])\n",
    "    \n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a8103d-e0bc-4278-9d31-b087111ca0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.25,1,0.25) #[0.25, 0.50, 0.75]\n",
    "thresholds_str = [\"-\"+(str(int(i*100))) for i in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950b8375-1b3e-442d-be5e-cceee402303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_group(value, groups):\n",
    "    for i, value_group in enumerate(groups):\n",
    "        if value < value_group:\n",
    "            return i\n",
    "    return i+1\n",
    "\n",
    "def write_file(X, f, groups):\n",
    "    f.write(f\"<http:{X['Subject']}>\\t{X['Predicate']}\\t<http:/{give_group(X['Object'], groups)}>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4177a3a8-4698-4281-af44-b03a18c5b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(root_source_FB+\"train.txt\", \"r\")\n",
    "f = open(root_data_FB+\"train.tsv\", \"w\")\n",
    "\n",
    "dic_predicate = {}\n",
    "\n",
    "for line in data: \n",
    "    line_split = line.split(\"\\n\")[0].split(\"\\t\")\n",
    "    if line_split[1] in numerical_predicate:\n",
    "        line_split[2] = float(line_split[2]) \n",
    "        line_split = tuple(line_split)\n",
    "        if line_split[1] in dic_predicate.keys():\n",
    "            dic_predicate[line_split[1]].add(line_split)\n",
    "        else : \n",
    "            dic_predicate[line_split[1]] = {line_split}\n",
    "    else:\n",
    "        f.write('<http:'+line_split[0]+'>\\t<http:'+line_split[1]+'>\\t'+'<http:'+line_split[2]+'>\\n')\n",
    "    \n",
    "data.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a06f084-388f-408b-96ca-5fe8743869ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(root_data_FB+\"train.tsv\", \"a\")\n",
    "\n",
    "for key in dic_predicate.keys():\n",
    "    tp_df = pd.DataFrame.from_dict(dic_predicate[key]).rename(columns={0: \"Subject\", 1: \"Predicate\", 2: \"Object\"})\n",
    "    tp_df_describe = tp_df[\"Object\"].quantile(thresholds)\n",
    "    tp_df.apply(write_file, args=(f, tp_df_describe), axis=1)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c961d454-55af-4ff5-9dac-f3300c616fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = check_output(f'java -jar ./../amie3.jar {root_data_FB+\"train.tsv\"}', shell=True)\n",
    "\n",
    "res_parsed = parse_amie(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140341d9-47b6-4074-9995-d736d6627217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46163"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6174c2c-7d25-49b9-8052-53504d8d63e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# res_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fb741-b154-4724-97ab-3c1ad7e830aa",
   "metadata": {},
   "source": [
    "### Number of numericals in the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c1e63fa-de23-4b4e-95a7-6eca19eda177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule with numerical :  6281\n",
      "Rule without numerical :  39882\n",
      "Rule with numerical in hypotheses :  6281\n",
      "Rule with numerical in conclusion :  6059\n"
     ]
    }
   ],
   "source": [
    "num_f = open(\"ST_num_rules.txt\", \"w\")\n",
    "symb_f = open(\"ST_symb_rules.txt\", \"w\")\n",
    "\n",
    "def predicate_is_numerical(atom, numerical_predicate):\n",
    "    return atom.predicate in numerical_predicate\n",
    "\n",
    "rule_with_numerical_in_hyp = 0\n",
    "rule_with_numerical_in_conc = 0\n",
    "rule_with_numerical = 0\n",
    "\n",
    "for rule in res_parsed:\n",
    "    num = False\n",
    "    for hyp in rule.hypotheses:\n",
    "        if predicate_is_numerical(hyp, numerical_predicate):\n",
    "            rule_with_numerical_in_hyp+=1\n",
    "            num = True\n",
    "            break\n",
    "    if predicate_is_numerical(rule.conclusion, numerical_predicate):\n",
    "        rule_with_numerical_in_conc+=1\n",
    "        num=True\n",
    "    if num:\n",
    "        rule_with_numerical += 1\n",
    "        num_f.write(str(rule)+\"\\n\")\n",
    "    else:\n",
    "        symb_f.write(str(rule)+\"\\n\")\n",
    "    \n",
    "print(\"Rule with numerical : \", rule_with_numerical)\n",
    "print(\"Rule without numerical : \", len(res_parsed) - rule_with_numerical)\n",
    "print(\"Rule with numerical in hypotheses : \", rule_with_numerical_in_hyp)\n",
    "print(\"Rule with numerical in conclusion : \", rule_with_numerical_in_conc)\n",
    "\n",
    "num_f.close()\n",
    "symb_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555a35b-ad79-498b-bfd7-9876754725cf",
   "metadata": {},
   "source": [
    "### Test the rules through test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9794da5d-edf0-4c0b-8c7f-959747bf7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(root_data_FB+\"train.tsv\", \"r\")\n",
    "f = open(root_data_FB+\"train_rdflib.nt\", \"w\")\n",
    "\n",
    "for line in data:\n",
    "    f.write(line.split(\"\\n\")[0]+\" . \\n\")\n",
    "\n",
    "data.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e30cdc7-25e0-408a-a5b1-308ca5d32652",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(root_source_FB+\"test.txt\", \"r\")\n",
    "\n",
    "set_instances_to_predict = set()\n",
    "\n",
    "for line in data:\n",
    "    line_splited = line.split(\"\\n\")[0].split(\"\\t\")\n",
    "    for i in range(len(line_splited)):\n",
    "        line_splited[i] = \"<http:\"+line_splited[i]+\">\"\n",
    "    set_instances_to_predict.add(tuple(line_splited))\n",
    "        \n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f95c12-527b-41ba-9909-604b5b7833f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59250\n"
     ]
    }
   ],
   "source": [
    "print(len(set_instances_to_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ebd2d77-2fb2-4549-80a9-4a6e446ca529",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_associated_to_query = {}\n",
    "\n",
    "for rule in res_parsed:\n",
    "    if rule.conclusion.predicate in rules_associated_to_query.keys():\n",
    "        rules_associated_to_query[rule.conclusion.predicate].add(rule)\n",
    "    else:\n",
    "        rules_associated_to_query[rule.conclusion.predicate] = set()\n",
    "        rules_associated_to_query[rule.conclusion.predicate].add(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24a12c08-c4b6-458c-bc34-88061112a617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N17e515580d334e1489f5e33acaa423c1 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = rdflib.Graph()\n",
    "g.parse(root_data_FB+\"train_rdflib.nt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d8518f7-0d2c-4aa6-a683-4aa92ce70be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rules_nicely(rule):\n",
    "    toprint = \"\"\n",
    "    for hyp in rule.hypotheses:\n",
    "        toprint += hyp.predicate+\" & \"\n",
    "    toprint = toprint[:-2]\n",
    "    toprint += \"=>\"+rule.conclusion.predicate\n",
    "    print(toprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25e7fc40-3ff5-4a16-a495-dcd05b24c25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process n°0 : Launched\n",
      "Process n°1 : Launched\n",
      "Process n°2 : Launched\n",
      "Process n°3 : Launched\n",
      "Process n°4 : Launched\n",
      "Process n°5 : Launched\n",
      "Process n°6 : Launched\n",
      "Process n°7 : Launched\n",
      "Process n°8 : Launched\n",
      "Value('cpt', 1)\n",
      "\n",
      "Process n°9 : LaunchedProcess n°10 : Launched\n",
      "Process n°11 : Launched\n",
      "Process n°12 : Launched\n",
      "Value('cpt', 1001)\n",
      "Value('cpt', 2001)\n",
      "Value('cpt', 3001)\n",
      "Value('cpt', 4001)\n",
      "Value('cpt', 5001)\n",
      "Value('cpt', 5002)\n",
      "Value('cpt', 7001)\n",
      "Process n°8 : Finished\n",
      "Value('cpt', 8000)\n",
      "Value('cpt', 9000)\n",
      "Process n°4 : Finished\n",
      "Process n°5 : Finished\n",
      "Process n°10 : Finished\n",
      "Process n°1 : Finished\n",
      "Process n°11 : Finished\n",
      "Process n°0 : Finished\n",
      "Process n°7 : Finished\n",
      "Process n°6 : Finished\n",
      "Process n°9 : Finished\n",
      "Process n°3 : Finished\n",
      "Process n°2 : Finished\n",
      "Process n°12 : Finished\n",
      "CPU times: user 14.5 s, sys: 1h 11min 26s, total: 1h 11min 40s\n",
      "Wall time: 1h 29min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def predict_instance(name, g, queue, prediction_per_instance_man, rules_associated_to_query, cpt, total_length, print_advancment, print_advancment_precise):\n",
    "    \n",
    "    print(f\"Process n°{name} : Launched\")\n",
    "    \n",
    "    while not queue.empty():\n",
    "        \n",
    "        instance = queue.get()\n",
    "        \n",
    "        dict_tp = {}\n",
    "        \n",
    "        if instance[1] in rules_associated_to_query.keys():\n",
    "            for rule in rules_associated_to_query[instance[1]]:\n",
    "                try:\n",
    "                    qres = g.query(create_query(rule, instance[2]))\n",
    "\n",
    "                    set_res = set()\n",
    "                    bool_res = False\n",
    "                    for row in qres:\n",
    "                        bool_res = True\n",
    "                        set_res.add(str(row.a))\n",
    "\n",
    "                    if bool_res:\n",
    "                        dict_tp[rule] = set_res\n",
    "            \n",
    "                except:\n",
    "                    print(create_query(rule, instance[2]))\n",
    "                    \n",
    "            prediction_per_instance_man[instance] = dict_tp\n",
    "            \n",
    "        else:\n",
    "            prediction_per_instance_man[instance] = {}\n",
    "        \n",
    "        cpt.value += 1\n",
    "        if (cpt.value/total_length > print_advancment.value ):\n",
    "            print(print_advancment.value*100+\" %\")\n",
    "            print_advancment.value+=0.1\n",
    "        if (cpt.value/total_length > print_advancment_precise.value):\n",
    "            print(print_advancment_precise.value*100+\" %\")\n",
    "            print_advancment_precise.value+=0.01\n",
    "        \n",
    "    print(f\"Process n°{name} : Finished\")   \n",
    "    \n",
    "q = Queue()\n",
    "prediction_per_instance = {}\n",
    "\n",
    "for instance in list(set_instances_to_predict):\n",
    "    q.put(instance)\n",
    "\n",
    "size_queue = q.qsize()\n",
    "\n",
    "print(\"Queue finished\")\n",
    "\n",
    "with Manager() as manager:\n",
    "\n",
    "    processes_to_create = multiprocessing.cpu_count()-3\n",
    "    processes = list()\n",
    "\n",
    "    prediction_per_instance_man = manager.dict()\n",
    "    cpt = manager.Value(\"cpt\",0)\n",
    "    print_advancment = manager.Value(\"print_advancment\", 0)\n",
    "    print_advancment_precise = manager.Value(\"print_advancment_precise\", 0.9)\n",
    "\n",
    "    for name in range(processes_to_create):\n",
    "        x = Process(target=predict_instance, args=(name, g, q, prediction_per_instance_man, rules_associated_to_query, cpt, size_queue, print_advancment, print_advancment_precise))\n",
    "        processes.append(x)\n",
    "        x.start()\n",
    "        \n",
    "    for index, process in enumerate(processes):\n",
    "        process.join()\n",
    "        \n",
    "    \n",
    "        \n",
    "    print(\"copy\")\n",
    "    \n",
    "    df_prediction = {}\n",
    "    \n",
    "    cpt = 0\n",
    "    advcement = 0.1\n",
    "    total_length = len(prediction_per_instance_man)\n",
    "    \n",
    "    del g\n",
    "\n",
    "    for prediction_instance in prediction_per_instance_man:\n",
    "        df_rules = {}\n",
    "        cpt += 1\n",
    "        for rule in prediction_per_instance_man[prediction_instance]:\n",
    "            df_rules[rule] = [set(prediction_per_instance_man[prediction_instance][rule]), rule.stdConfidence, rule.pcaConfidence]\n",
    "        df_prediction[prediction_instance] = pd.DataFrame.from_dict(df_rules, orient=\"index\", columns=[\"Prediction\", \"Std Confidence\", \"Pca Confidence\"])\n",
    "        \n",
    "        if (cpt/total_length > advcement):\n",
    "            print(advcement *100, \"%\")\n",
    "            advcement+=0.1\n",
    "        \n",
    "    print(\"----- Democracy -----\")\n",
    "    hit_at(df_prediction, democracy, 1)\n",
    "    hit_at(df_prediction, democracy, 5)\n",
    "    hit_at(df_prediction, democracy, 10)\n",
    "    hit_at(df_prediction, democracy, 1000)\n",
    "\n",
    "    print(\"----- Expert -----\")\n",
    "    hit_at(df_prediction, expert, 1)\n",
    "    hit_at(df_prediction, expert, 5)\n",
    "    hit_at(df_prediction, expert, 10)\n",
    "    hit_at(df_prediction, expert, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989ea3d-6939-4612-beed-efd85a654a37",
   "metadata": {},
   "source": [
    "len(prediction_per_instance.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b2547-9b2e-4049-b0f0-91babf0468e4",
   "metadata": {},
   "source": [
    "df_prediction = {}\n",
    "\n",
    "for prediction_instance in prediction_per_instance:\n",
    "    df_rules = {}\n",
    "    for rule in prediction_per_instance[prediction_instance]:\n",
    "        df_rules[rule] = [set(prediction_per_instance[prediction_instance][rule]), rule.stdConfidence, rule.pcaConfidence]\n",
    "    df_prediction[prediction_instance] = pd.DataFrame.from_dict(df_rules, orient=\"index\", columns=[\"Prediction\", \"Std Confidence\", \"Pca Confidence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3b651-ea37-4f86-9aa2-4d90c59b5cea",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(\"----- Democracy -----\")\n",
    "hit_at(df_prediction, democracy, 2)\n",
    "hit_at(df_prediction, democracy, 5)\n",
    "hit_at(df_prediction, democracy, 10)\n",
    "hit_at(df_prediction, democracy, 1000)\n",
    "\n",
    "print(\"----- Expert -----\")\n",
    "hit_at(df_prediction, expert, 2)\n",
    "hit_at(df_prediction, expert, 5)\n",
    "hit_at(df_prediction, expert, 10)\n",
    "hit_at(df_prediction, expert, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad82855a-420c-46e5-85bc-42d89517380f",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14773090-9e2a-40cb-a18d-feda54c81ad0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "\n",
    "def predict_instance(name, g, instances, prediction_per_instance_man, rules_associated_to_query, cpt, total_length, print_advancment):\n",
    "    \n",
    "    print(f\"Process n°{name} : Launched\")\n",
    "    \n",
    "    for instance in instances:\n",
    "        \n",
    "        dict_tp = {}\n",
    "        if instance[1] in rules_associated_to_query.keys():\n",
    "            for rule in rules_associated_to_query[instance[1]]:\n",
    "                try:\n",
    "                    qres = g.query(create_query(rule, instance[2]))\n",
    "                    print(create_query(rule, instance[2]))\n",
    "\n",
    "                    set_res = set()\n",
    "                    bool_res = False\n",
    "                    for row in qres:\n",
    "                        bool_res = True\n",
    "                        set_res.add(str(row.a))\n",
    "\n",
    "                    if bool_res:\n",
    "                        dict_tp[rule] = set_res\n",
    "            \n",
    "                except:\n",
    "                    print(create_query(rule, instance[2]))\n",
    "                    \n",
    "            prediction_per_instance_man[instance] = dict_tp\n",
    "            \n",
    "        else:\n",
    "            prediction_per_instance_man[instance] = {}\n",
    "        \n",
    "        cpt.value += 1\n",
    "        if (cpt.value/total_length > print_advancment.value):\n",
    "            print(cpt)\n",
    "            print_advancment.value+=0.1\n",
    "        \n",
    "    print(f\"Process n°{name} : Finished\")\n",
    "\n",
    "prediction_per_instance_test = {}\n",
    "\n",
    "size_queue = len(list(set_instances_to_predict)[:10])\n",
    "\n",
    "with Manager() as manager:\n",
    "\n",
    "    processes_to_create = 1#multiprocessing.cpu_count()-3\n",
    "    processes = list()\n",
    "\n",
    "    prediction_per_instance_man = manager.dict()\n",
    "    cpt = manager.Value(\"cpt\",0)\n",
    "    print_advancment = manager.Value(\"print_advancment\",0)\n",
    "    \n",
    "    instances_list = list(set_instances_to_predict)[:1]\n",
    "\n",
    "    for name in range(processes_to_create):\n",
    "        x = Process(target=predict_instance, args=(name, g, instances_list[int(np.floor(name*len(instances_list)/processes_to_create)): int(np.floor((name+1)*len(instances_list)/processes_to_create))], \n",
    "                                                   prediction_per_instance_man, rules_associated_to_query, cpt, size_queue, print_advancment))\n",
    "        processes.append(x)\n",
    "        x.start()\n",
    "        \n",
    "    for index, process in enumerate(processes):\n",
    "        process.join()\n",
    "\n",
    "    prediction_per_instance_test = prediction_per_instance_man.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513438fa-dd4b-470d-9f6d-9c07be54db68",
   "metadata": {},
   "source": [
    "# DB15K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f31362-e81b-42f0-82e1-9ea89591869b",
   "metadata": {},
   "source": [
    "data = open(root_source_DB+\"numericals.txt\", \"r\")\n",
    "\n",
    "numerical_predicate = set()\n",
    "\n",
    "for predicate in data:\n",
    "    numerical_predicate.add(predicate.split(\"\\n\")[0])\n",
    "    \n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0fd79-3bbf-49cb-a36d-638126c6d9c0",
   "metadata": {},
   "source": [
    "thresholds = np.arange(0.25,1,0.25) #[0.25, 0.50, 0.75]\n",
    "thresholds_str = [\"-\"+(str(int(i*100))) for i in thresholds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef2ba7-d268-4b36-8f29-7fefc76b3be9",
   "metadata": {},
   "source": [
    "def give_group(value, groups):\n",
    "    for i, value_group in enumerate(groups):\n",
    "        if value < value_group:\n",
    "            return i\n",
    "    return i+1\n",
    "\n",
    "def write_file(X, f, groups):\n",
    "    f.write(f\"{X['Subject']}\\t{X['Predicate']}\\t{give_group(X['Object'], groups)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e191b-00fd-4182-ade8-b27d8a9c641b",
   "metadata": {},
   "source": [
    "data = open(root_source_DB+\"train.txt\", \"r\")\n",
    "f = open(store_data_DB, \"w\")\n",
    "\n",
    "dic_predicate = {}\n",
    "\n",
    "for line in data: \n",
    "    line_split = line.split(\"\\n\")[0].split(\" \")\n",
    "    if len(line_split) == 1:\n",
    "        line_split = line.split(\"\\n\")[0].split(\"\\t\")\n",
    "    if line_split[1] in numerical_predicate:\n",
    "        line_split[2] = float(line_split[2]) \n",
    "        line_split = tuple(line_split)\n",
    "        if line_split[1] in dic_predicate.keys():\n",
    "            dic_predicate[line_split[1]].add(line_split)\n",
    "        else : \n",
    "            dic_predicate[line_split[1]] = {line_split}\n",
    "    else:\n",
    "        f.write(line)\n",
    "    \n",
    "data.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a53897-6a00-4655-af39-5bccf7165721",
   "metadata": {},
   "source": [
    "f = open(store_data_DB, \"a\")\n",
    "\n",
    "for key in dic_predicate.keys():\n",
    "    tp_df = pd.DataFrame.from_dict(dic_predicate[key]).rename(columns={0: \"Subject\", 1: \"Predicate\", 2: \"Object\"})\n",
    "    tp_df_describe = tp_df[\"Object\"].quantile(thresholds)\n",
    "    tp_df.apply(write_file, args=(f, tp_df_describe), axis=1)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626ca0e-ba58-46e7-9664-29d19ca78815",
   "metadata": {
    "tags": []
   },
   "source": [
    "res = check_output(f'java -jar ./../amie3.jar {store_data_DB}', shell=True)\n",
    "\n",
    "res_parsed = parse_amie(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec953a-eeb5-4645-813f-02fc78b2025e",
   "metadata": {},
   "source": [
    "len(res_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf0e1f4-51c8-4a4d-a238-83fe71e71728",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "res_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cddb8-7bc5-43d9-8bbb-306bf9766994",
   "metadata": {},
   "source": [
    "### Number of numericals in the rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee91653-b6ab-4fdd-9842-9652181cb79b",
   "metadata": {},
   "source": [
    "def predicate_is_numerical(atom, numerical_predicate):\n",
    "    return atom.predicate in numerical_predicate\n",
    "\n",
    "rule_with_numerical_in_hyp = 0\n",
    "rule_with_numerical_in_conc = 0\n",
    "rule_with_numerical = 0\n",
    "\n",
    "for rule in res_parsed:\n",
    "    num = False\n",
    "    for hyp in rule.hypotheses:\n",
    "        if predicate_is_numerical(hyp, numerical_predicate):\n",
    "            rule_with_numerical_in_hyp+=1\n",
    "            num = True\n",
    "            break\n",
    "    if predicate_is_numerical(rule.conclusion, numerical_predicate):\n",
    "        rule_with_numerical_in_conc+=1\n",
    "        num=True\n",
    "    if num:\n",
    "        rule_with_numerical += 1\n",
    "    \n",
    "print(\"Rule with numerical : \", rule_with_numerical)\n",
    "print(\"Rule without numerical : \", len(res_parsed) - rule_with_numerical)\n",
    "print(\"Rule with numerical in hypotheses : \", rule_with_numerical_in_hyp)\n",
    "print(\"Rule with numerical in conclusion : \", rule_with_numerical_in_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b48c0-221a-4459-94f7-17f37d18a843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
